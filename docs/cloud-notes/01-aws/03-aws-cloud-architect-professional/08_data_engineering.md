---
title: "Engenharia de dados"
sidebar_position: 8
---  
## AWS Kinesis

O **Amazon Kinesis** √© um servi√ßo gerenciado da AWS que facilita a coleta, processamento e an√°lise de fluxos (**streams**) de dados em **tempo real**. √â amplamente utilizado para monitoramento de logs, m√©tricas, an√°lise de dados de IoT e processamento de Big Data. O Kinesis √© frequentemente comparado ao **Apache Kafka**, pois tamb√©m √© uma solu√ß√£o de streaming em tempo real.

---

> **Principais Caracter√≠sticas**
- Processamento de grandes volumes de dados em tempo real.
- Alternativa da AWS ao **Apache Kafka**.
- Alta disponibilidade: **Dados replicados em 3 zonas de disponibilidade (AZs)** para maior resili√™ncia.
- Integrado a ferramentas de Big Data como **Apache Spark** e **NiFi**.
- Dados organizados em **shards**, garantindo capacidade de processamento distribu√≠da.
- Suporte a **m√∫ltiplos consumidores** simult√¢neos.  

:::note Importante
Os dados no Kinesis s√£o imut√°veis ‚Äî uma vez gravados, n√£o podem ser alterados ou exclu√≠dos.
:::

---

**Arquitetura Geral do Amazon Kinesis**

- Um **produtor** envia um **record** para o **Kinesis Data Stream**.
- O stream distribui o **record** para um ou mais consumidores.
- Ordena√ß√£o garantida por **chaves de parti√ß√£o** (Partition Keys). Registros com a mesma chave v√£o para o mesmo **shard**.

![Amazon Kinesis](assets/product-page-diagram_Amazon-Kinesis_Evolve-from-batch-to-real-time-Analytics.d7ed76be304a30be5720fd159469f157e7c09ede.png)

---

> **Tipos de Aplica√ß√µes do Amazon Kinesis**

- **Kinesis Data Streams**: Captura, processa e armazena fluxos de dados.  
- **Kinesis Data Firehose**: Carrega dados para armazenamentos na AWS como **S3**, **Redshift**, **OpenSearch** e **Splunk**.  
- **Kinesis Data Analytics**: Analisa fluxos de dados em tempo real usando **SQL** e **Apache Flink**.  
- **Kinesis Video Streams**: Captura, processa e armazena fluxos de v√≠deo em tempo real.  

---

> **Kinesis Data Streams**

- Ideal para ingest√£o e processamento de grandes volumes de dados com baixa lat√™ncia.  
- Cobran√ßa baseada em **shards provisionados**. Cada shard permite:  
  - **Entrada:** 1 MB/s ou 1.000 registros por segundo.  
  - **Sa√≠da:** 2 MB/s para m√∫ltiplos consumidores.  
- Reten√ß√£o de dados de **1 a 365 dias**.  
- **Produtores**:
  - Lambda, Kinesis Data Firehose, Kinesis Data Analytics.  
  - **AWS SDK** e **Kinesis Producer Library (KPL)** ‚Äî suportam compress√£o e batch.  
  - **Kinesis Agent** ‚Äî coleta logs e envia ao Kinesis Data Streams ou Firehose.  
- **Consumidores**:
  - **AWS Lambda**, Kinesis Client Library (KCL) e AWS SDK.  
  - Suporte a leitura paralela, checkpoint e coordena√ß√£o de leitura.  
- **Modos de Opera√ß√£o**:
  - **Sob Demanda:** Escala automaticamente com a carga. Pagamento por GB de I/O.  
  - **Provisionado:** Quantidade de shards definida manualmente. Pagamento por hora de shard e I/O por GB.  
- **Padr√µes de Consumo**:
  - **Batch** ou **mensagem por mensagem**.  

:::tip Dica
Se precisar de processamento paralelo, use o **Kinesis Client Library (KCL)** para leitura distribu√≠da.
:::

![data-streams](assets/image-20210903054120413.png)

---

> **Kinesis Data Firehose**

- Carrega dados para armazenamentos da AWS como **S3**, **Redshift**, **OpenSearch** e **Splunk**.  
- Servi√ßo totalmente gerenciado, com escalabilidade autom√°tica e arquitetura **serverless**.  
- Cobran√ßa apenas pelos dados processados.  
- Funciona pr√≥ximo do tempo real, pois utiliza um buffer para otimiza√ß√£o:  
  - Buffer baseado em **tempo** ou **tamanho**.  
  - Caso seja necess√°rio tempo real puro, utilize o **AWS Lambda** para pr√©-processamento.  

**Exemplo de Processo de Entrega**:  
![image-20230221065515012](assets/image-20230221065515012.png)

**Diferen√ßa entre Data Streams e Firehose**:  
![image-20230221070204566](assets/image-20230221070204566.png)

:::caution Aten√ß√£o
O Firehose n√£o possui reten√ß√£o de dados para reprocessamento, como o **Kinesis Data Streams**.
:::

---

> **Kinesis Data Analytics**

- An√°lise de fluxos de dados em **tempo real** com **SQL** e **Apache Flink**.  
- Servi√ßo gerenciado e altamente escal√°vel.  
- Cobran√ßa baseada no volume de dados consumidos.  
- Integra√ß√£o com **AWS Lambda** para pr√©-processamento dos dados.  
- Permite consultas cont√≠nuas e cria√ß√£o de dashboards de monitoramento em tempo real.  
- Uso de **IAM** para controlar o acesso √†s origens e destinos dos dados processados.  

**Aplica√ß√µes Comuns**:
- An√°lise de per√≠odos de tempo.  
- Monitoramento e dashboards em tempo real.  
- M√©tricas de IoT e logs de auditoria.  

![data-analytics](assets/image-20210903055735875.png)

:::info Nota
O uso de SQL simplifica a an√°lise para usu√°rios que n√£o t√™m familiaridade com frameworks complexos como Apache Flink.
:::

---

> **Arquiteturas de Refer√™ncia com Amazon Kinesis**

**Pipeline de Dados em Tempo Real**  
![image-20230221071407686](assets/image-20230221071407686.png)

**Solu√ß√µes de Baixo Custo para Tempo Real**  
![image-20230221071638191](assets/image-20230221071638191.png)

**Compara√ß√£o com Outras Solu√ß√µes de Streaming**  
![image-20230221072024210](assets/image-20230221072024210.png)

---

> **Resumo dos Limites do Kinesis Data Streams**

- Limite padr√£o de shards: **500 shards por conta**, podendo ser aumentado.  
- Limite de dados de entrada: **1 MB/s** por shard.  
- Limite de dados de sa√≠da: **2 MB/s** por shard para m√∫ltiplos consumidores.  

![image-20230221064945510](assets/image-20230221064945510.png)

:::warning Limita√ß√µes
Caso precise de maior throughput, √© necess√°rio dividir a carga entre m√∫ltiplos shards ou aumentar o n√∫mero de shards provisionados.
:::

---

:::tip **Dica para a prova üéØ**  

> Quest√µes sobre o **Kinesis Data Streams** frequentemente abordam cen√°rios de ingest√£o de dados em tempo real com alta escala, pedindo para identificar configura√ß√µes corretas de shards ou modos de opera√ß√£o.  

üìå Uma empresa deseja processar **logs de acesso de milh√µes de usu√°rios simult√¢neos** em tempo real. Qual modo de opera√ß√£o do Kinesis Data Streams √© mais adequado para garantir escalabilidade autom√°tica sem gerenciamento manual de shards?  
- ‚úÖ **Modo Sob Demanda**  

üìå Para um aplicativo que coleta **1.500 registros por segundo**, qual deve ser o n√∫mero m√≠nimo de shards provisionados para garantir a ingest√£o correta dos dados?  
- ‚úÖ **2 shards** (Cada shard suporta at√© 1.000 registros/s)  

---

> Perguntas sobre **Kinesis Data Firehose** geralmente envolvem entrega de dados para destinos como **S3, Redshift ou OpenSearch**, focando em otimiza√ß√£o de buffer e custos.  

üìå Uma equipe de an√°lise de dados deseja carregar informa√ß√µes em tempo quase real no **Amazon S3**. O volume de dados √© pequeno, e a lat√™ncia precisa ser m√≠nima. O que deve ser configurado no Firehose para otimizar a entrega?  
- ‚úÖ **Buffer com menor tempo poss√≠vel (60 segundos)** e tamanho m√≠nimo de **1 MB**.  

üìå Uma empresa deseja pr√©-processar os dados antes de entreg√°-los ao **Amazon Redshift**. Qual recurso do Firehose deve ser utilizado?  
- ‚úÖ **AWS Lambda para transforma√ß√£o dos dados**.  

---

> Quest√µes sobre **Kinesis Data Analytics** costumam testar conhecimentos sobre consultas **SQL** em streams de dados, integra√ß√£o com **AWS Lambda** e monitoramento de m√©tricas.  

üìå Uma startup deseja analisar em tempo real dados de sensores IoT para detec√ß√£o de falhas. Qual servi√ßo √© o mais indicado para processar e analisar esses dados utilizando **SQL**?  
- ‚úÖ **Kinesis Data Analytics**  

üìå Para gerar alarmes com base em eventos processados no **Kinesis Data Analytics**, qual servi√ßo pode ser utilizado para integra√ß√£o imediata?  
- ‚úÖ **AWS Lambda** para resposta em tempo real.  

:::

---

## AWS MSK

O **Amazon MSK** (Managed Streaming for Apache Kafka) √© um servi√ßo gerenciado da AWS baseado no **Apache Kafka**, que facilita a cria√ß√£o e execu√ß√£o de clusters Kafka altamente dispon√≠veis, seguros e escal√°veis na nuvem da AWS. Ele √© projetado para oferecer todas as funcionalidades do Apache Kafka, mas com gerenciamento simplificado e integra√ß√£o nativa com outros servi√ßos da AWS.

![Amazon MSK](assets/image-20230221072716148.png)

---

> Principais Caracter√≠sticas  
- **Servi√ßo gerenciado de Kafka**: A AWS gerencia a infraestrutura subjacente, incluindo provisionamento, atualiza√ß√µes de software e manuten√ß√£o de hardware.  
- Alternativa ao **Amazon Kinesis** para processamento de dados em tempo real.  
- **Armazenamento persistente em EBS**: Dados armazenados em **volumes EBS** pelo tempo que o cliente desejar, garantindo durabilidade e resili√™ncia.  
- **Alta disponibilidade**: Suporte a m√∫ltiplas zonas de disponibilidade (Multi-AZ) para alta disponibilidade.  
- Op√ß√£o de implementa√ß√£o **Serverless**, eliminando a necessidade de provisionamento manual de clusters.  
- Integra√ß√£o nativa com servi√ßos da AWS, facilitando a constru√ß√£o de pipelines de dados escal√°veis e seguros.  

---

> Consumidores no Amazon MSK  
Os dados armazenados nos t√≥picos Kafka do MSK podem ser consumidos por:  
- **Aplica√ß√µes personalizadas** que leem diretamente dos t√≥picos usando clientes Kafka padr√£o.  
- **Kinesis Data Analytics**: Processamento avan√ßado de streams de dados.  
- **AWS Glue**: Transforma√ß√£o e integra√ß√£o de dados.  
- **AWS Lambda**: Processamento de eventos em tempo real sem necessidade de infraestrutura gerenciada.  

---

> Diferen√ßas entre MSK e Amazon Kinesis  
O Amazon MSK e o Amazon Kinesis t√™m casos de uso semelhantes para processamento de dados em tempo real, mas diferem em arquitetura, gerenciamento e casos de uso espec√≠ficos.

![Diferen√ßa entre MSK e Kinesis](assets/image-20230221072810544.png)

- **MSK** √© indicado quando h√° necessidade de compatibilidade total com o ecossistema Apache Kafka ou integra√ß√£o com sistemas j√° baseados em Kafka.  
- **Kinesis** √© uma solu√ß√£o mais f√°cil de configurar e gerenciar para quem j√° est√° imerso no ecossistema AWS.  

---

:::info **Nota Importante üìò**  
A escolha entre **Amazon MSK** e **Amazon Kinesis** depende dos requisitos espec√≠ficos de integra√ß√£o, complexidade operacional e compatibilidade com ferramentas externas. Se sua equipe j√° utiliza Kafka on-premises ou precisa de compatibilidade completa com APIs do Kafka, o **Amazon MSK** pode ser a melhor escolha.  
:::

---

:::tip **Dica para a prova üéØ**

> Quest√µes relacionadas ao **Amazon MSK** frequentemente abordam compara√ß√µes com o **Amazon Kinesis**, gerenciamento de clusters Kafka e cen√°rios de integra√ß√£o com outros servi√ßos da AWS.

üìå Uma equipe de desenvolvimento utiliza Kafka on-premises para processamento de dados em tempo real. Eles desejam migrar para a AWS mantendo a compatibilidade com seu c√≥digo atual e minimizando a necessidade de mudan√ßas significativas. Qual servi√ßo AWS √© mais adequado?  
- ‚úÖ Amazon MSK (Managed Streaming for Apache Kafka)  

üìå Uma aplica√ß√£o precisa processar grandes volumes de dados em tempo real com alta taxa de ingest√£o. A equipe deseja evitar o gerenciamento complexo de clusters Kafka e prefere uma solu√ß√£o serverless totalmente gerenciada. Qual servi√ßo √© recomendado?  
- ‚úÖ Amazon Kinesis Data Streams  

---

> O **Amazon MSK Serverless** √© uma alternativa para reduzir a complexidade de provisionamento e gerenciamento de clusters Kafka, ajustando automaticamente a capacidade de acordo com a demanda.

üìå Durante um evento de marketing, o tr√°fego de dados no cluster Kafka aumenta de forma imprevis√≠vel. A equipe quer garantir a continuidade sem precisar redimensionar manualmente o cluster. Qual modo de opera√ß√£o do Amazon MSK √© mais indicado?  
- ‚úÖ Amazon MSK Serverless  

üìå Um cliente deseja integrar seu cluster MSK com servi√ßos de an√°lise de dados em tempo real da AWS. Qual ferramenta √© recomendada para processar e analisar fluxos de dados diretamente do MSK?  
- ‚úÖ Kinesis Data Analytics ou AWS Lambda  

:::

---

## AWS Batch

O **AWS Batch** √© um servi√ßo gerenciado da AWS que permite a execu√ß√£o de trabalhos em lote (**batch jobs**) utilizando **imagens Docker**. Ele simplifica o planejamento, a execu√ß√£o e o dimensionamento de workloads de processamento de dados sem a necessidade de gerenciar infraestrutura de cluster complexa. O pagamento √© baseado apenas nos recursos utilizados, como inst√¢ncias **EC2**, **Fargate** e **Spot Instances**.

---

> **Principais Caracter√≠sticas**
- Suporte a execu√ß√£o de **imagens Docker** para jobs em lote.
- Cobran√ßa apenas pelos recursos computacionais utilizados.
- Integra√ß√£o com **AWS Fargate**, eliminando a necessidade de provisionar e gerenciar clusters.
- Suporte a **EC2** e **Spot Instances** para execu√ß√£o na VPC.
- Possibilidade de utilizar **EventBridge** para agendamento de jobs.
- Integra√ß√£o com **AWS Step Functions** para orquestra√ß√£o de workflows complexos.

---

> **Op√ß√µes de Execu√ß√£o no AWS Batch**
- **AWS Fargate:** Execu√ß√£o serverless sem a necessidade de configurar e gerenciar inst√¢ncias ou clusters.  
- **Inst√¢ncias Provisionadas (EC2 e Spot):** Possibilidade de maior controle sobre a infraestrutura e otimiza√ß√£o de custos usando Spot Instances.  
  ![image-20230221174406433](assets/image-20230221174406433.png)

---

> **Casos de Uso**
- **Processamento de imagens em lote:** Gera√ß√£o de miniaturas, compress√£o de imagens ou renderiza√ß√£o de v√≠deos.  
- **Execu√ß√£o de jobs concorrentes:** Processamento paralelo de grandes volumes de dados.  
- **An√°lises cient√≠ficas e simula√ß√µes:** Modelagem matem√°tica e simula√ß√£o de cen√°rios complexos.  

---

> **Alta Performance com AWS Batch**
- O AWS Batch suporta execu√ß√£o de **multi-node parallel jobs** para workloads de alta performance.  
  - Distribui√ß√£o da carga de trabalho em v√°rias inst√¢ncias.  
  - **N√£o suporta inst√¢ncias Spot** para alta performance.  
  - Integra√ß√£o com **Placement Groups** para otimiza√ß√£o de baixa lat√™ncia de rede e alto desempenho.  

---

> **Diferen√ßa entre AWS Batch e AWS Lambda**
- O **AWS Batch** √© indicado para workloads de longa dura√ß√£o, uso intensivo de CPU ou mem√≥ria e com necessidade de controle detalhado da infraestrutura.  
- O **AWS Lambda** √© mais adequado para tarefas curtas, baseadas em eventos e com escalabilidade autom√°tica.  
  ![image-20230221174255199](assets/image-20230221174255199.png)

---

> **Solu√ß√µes de Arquitetura com AWS Batch**
- **Cria√ß√£o de Thumbnails:** Automa√ß√£o de gera√ß√£o de miniaturas de imagens em massa.  
  ![image-20230221173936781](assets/image-20230221173936781.png)

---

:::tip **Dica para a prova üéØ - AWS Batch**  

> Quest√µes sobre **AWS Batch** frequentemente abordam cen√°rios de processamento em lote, escolha de tipos de inst√¢ncia (EC2, Fargate, Spot) e casos de uso para jobs de alta performance.  

üìå Uma equipe de an√°lise de dados precisa processar grandes volumes de dados diariamente. O processamento deve ocorrer em hor√°rios definidos e minimizar custos. Qual estrat√©gia de execu√ß√£o no AWS Batch √© mais indicada?  
- ‚úÖ Uso de **Spot Instances** para redu√ß√£o de custos e agendamento com **EventBridge**.  

üìå Sua empresa precisa executar simula√ß√µes complexas e altamente paralelas, exigindo v√°rias inst√¢ncias trabalhando juntas. Qual recurso do AWS Batch atende melhor a esse cen√°rio?  
- ‚úÖ **Multi-node parallel jobs** com inst√¢ncias EC2 provisionadas, garantindo comunica√ß√£o entre os n√≥s.  

---

> O AWS Batch √© capaz de integrar com **AWS Step Functions** para orquestrar workflows complexos. Entender a integra√ß√£o entre esses servi√ßos √© importante para a certifica√ß√£o.  

üìå Um fluxo de trabalho envolve v√°rias etapas de processamento de dados, onde cada etapa depende da conclus√£o da anterior. Qual abordagem pode ser utilizada para orquestrar o fluxo com o AWS Batch?  
- ‚úÖ Utilizar **AWS Step Functions** para coordenar a execu√ß√£o dos jobs no Batch.  

üìå Um projeto precisa de processamento r√°pido de pequenas tarefas acionadas por eventos e alta escalabilidade autom√°tica. O AWS Batch √© adequado para esse cen√°rio?  
- ‚ùå N√£o. O uso do **AWS Lambda** seria mais apropriado para pequenas tarefas baseadas em eventos.  

---

> Aten√ß√£o √†s diferen√ßas entre **AWS Batch** e **AWS Lambda**. Quest√µes costumam abordar quando usar cada servi√ßo de maneira mais eficiente.  

üìå Sua aplica√ß√£o precisa processar milhares de imagens de forma r√°pida e econ√¥mica, sem se preocupar com a infraestrutura subjacente. Qual servi√ßo utilizar?  
- ‚úÖ **AWS Lambda** para processamento serverless, especialmente se cada execu√ß√£o levar menos de 15 minutos.  

:::

---

## AWS EMR

O **Amazon EMR** (Elastic MapReduce) √© um servi√ßo gerenciado da AWS para processamento de grandes volumes de dados utilizando frameworks como **Apache Hadoop**, **Spark**, **HBase**, **Presto** e **Flink**. Ele √© amplamente utilizado em cen√°rios de **Big Data**, **Machine Learning** e **Web Indexing**, sendo capaz de processar petabytes de dados de forma r√°pida e econ√¥mica.

---

> Principais Caracter√≠sticas  
- Cria√ß√£o de clusters Hadoop para an√°lise de grandes volumes de dados.  
- Capacidade de escalar automaticamente utilizando **Spot Instances**, reduzindo custos de processamento.  
- Suporte a frameworks populares de Big Data: **Apache Spark**, **HBase**, **Presto**, **Flink**.  
- Pode ser implantado em centenas de inst√¢ncias EC2 para maximizar a capacidade de processamento.  
- Uso recomendado em **Single AZ** para maximizar a performance, evitando lat√™ncia de comunica√ß√£o entre zonas de disponibilidade.  
- Suporte a armazenamento tempor√°rio via **EBS** com sistema de arquivos **HDFS (Hadoop File System)**.  
- Integra√ß√£o nativa com **S3 (EMRFS)** para armazenamento de longo prazo, garantindo persist√™ncia e durabilidade dos dados.  
- Integra√ß√µes adicionais com **DynamoDB** para consultas r√°pidas e armazenamento de dados estruturados.  

---

> Estrutura de N√≥s (Nodes) no Amazon EMR  
O cluster EMR √© composto por tr√™s tipos de n√≥s:  
- **Master Node:** Coordena o cluster, distribuindo as tarefas para os outros n√≥s.  
- **Core Nodes:** Executam tarefas de processamento e armazenam dados no **HDFS**.  
- **Task Nodes:** Executam tarefas de processamento, mas n√£o armazenam dados no **HDFS**.  

![Tipos de Nodes e Pre√ßos](assets/image-20230221175637124.png)

---

> Configura√ß√µes de Inst√¢ncias  
O Amazon EMR oferece dois modelos principais para configurar as inst√¢ncias dos n√≥s:  

**1. Uniform Instance Group:**  
- Define um √∫nico tipo de inst√¢ncia para cada fun√ß√£o do n√≥ (Master, Core, Task).  
- Op√ß√µes de compra: **On-Demand** ou **Spot Instances**.  
- Suporte a **Auto Scaling** para ajustar automaticamente a capacidade com base na demanda.  

**2. Instance Fleet:**  
- Maior flexibilidade ao permitir combinar diferentes tipos de inst√¢ncias (On-Demand e Spot).  
- Permite definir um mix de inst√¢ncias para otimizar custos.  
- **N√£o possui Auto Scaling** autom√°tico; a expans√£o do cluster deve ser gerenciada manualmente.  

---

> Armazenamento no EMR  
- **EBS (HDFS):** Utilizado para armazenamento tempor√°rio de dados enquanto o cluster est√° em execu√ß√£o.  
- **S3 (EMRFS):** Armazenamento de longo prazo com alta durabilidade. Ideal para persist√™ncia de dados.  
- **DynamoDB:** Usado para consultas r√°pidas e armazenamento de dados n√£o relacionais.  

---

> Caso de Uso  
- Processamento de grandes volumes de dados para an√°lises em tempo quase real.  
- Treinamento de modelos de Machine Learning em larga escala.  
- Indexa√ß√£o e an√°lise de conte√∫do da web.  
- An√°lise de logs de servidores ou eventos de dispositivos IoT.  

---

:::note **Integra√ß√µes e Ferramentas**  
- **AWS Glue:** Pode ser integrado ao EMR para cat√°logos de dados e ETL (Extract, Transform, Load).  
- **AWS Lambda:** Processamento de dados em tempo real para ingest√£o no cluster EMR.  
- **Amazon Athena:** Consultas SQL sobre dados armazenados no S3 tratados pelo EMR.  
- [Documenta√ß√£o Oficial do EMR](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html)  
:::

---

:::caution **Aten√ß√£o!**  
Implanta√ß√µes multi-AZ podem gerar lat√™ncia na comunica√ß√£o entre os n√≥s do cluster, impactando negativamente a performance.  
:::

---

:::tip **Dica para a prova üéØ**

> Quest√µes sobre **Amazon EMR** geralmente abordam casos de uso para **processamento de Big Data**, otimiza√ß√£o de custos com **Spot Instances** e integra√ß√µes com outros servi√ßos AWS, como **S3** e **DynamoDB**.

üìå Uma empresa precisa processar grandes volumes de dados utilizando Apache Spark para an√°lise de logs. O processamento precisa ser econ√¥mico, e os dados devem ser armazenados de forma dur√°vel. Qual a configura√ß√£o recomendada?  
- ‚úÖ Utilizar um cluster EMR com **Spot Instances** para reduzir custos e armazenar os dados no **S3** via EMRFS para persist√™ncia.

---

> O uso de **Instance Fleet** no EMR permite maior flexibilidade na escolha de inst√¢ncias, mas pode limitar a escalabilidade autom√°tica.

üìå Um time de cientistas de dados deseja criar um cluster EMR altamente flex√≠vel para testes explorat√≥rios, utilizando diferentes tipos de inst√¢ncias EC2. Eles n√£o querem depender de escalabilidade autom√°tica. Qual a abordagem correta?  
- ‚úÖ Configurar o cluster EMR com **Instance Fleet** para combinar inst√¢ncias On-Demand e Spot manualmente.

---

> A escolha entre **Single AZ** e **Multi AZ** pode impactar diretamente a performance do cluster EMR.

üìå Para minimizar a lat√™ncia durante o processamento de grandes volumes de dados em tempo real, qual a melhor pr√°tica para configurar a implanta√ß√£o do cluster EMR?  
- ‚úÖ Implantar o cluster EMR em **Single AZ** para evitar lat√™ncia de comunica√ß√£o entre zonas de disponibilidade.

---

> O **HDFS** √© utilizado para armazenamento tempor√°rio em clusters EMR, enquanto o **S3** √© recomendado para persist√™ncia de dados a longo prazo.

üìå Uma empresa deseja armazenar dados processados por um cluster EMR de forma dur√°vel e acess√≠vel por outras aplica√ß√µes anal√≠ticas. Qual a melhor pr√°tica?  
- ‚úÖ Utilizar o **EMRFS** para salvar os dados diretamente no **Amazon S3**, garantindo durabilidade e acessibilidade.

---

> O **AWS Glue** pode ser integrado ao EMR para cat√°logos de dados e tarefas de ETL.

üìå Um analista de dados precisa executar transforma√ß√µes complexas de ETL em um grande volume de dados antes de armazen√°-los no S3. Qual combina√ß√£o de servi√ßos √© recomendada?  
- ‚úÖ Utilizar **AWS Glue** para catalogar e transformar os dados e um cluster **EMR** para processar grandes volumes com **Apache Spark**.

:::

---

## AWS Glue

- Servi√ßo gerenciado de **ETL** (*Extract, Transform, Load*), que facilita a prepara√ß√£o e transforma√ß√£o de dados para an√°lises.  
- √â um servi√ßo **serverless**, ou seja, n√£o h√° necessidade de gerenciar infraestrutura. Oferece tr√™s componentes principais:  
- Componentes do AWS Glue:
  - **AWS Crawler:** Rastreia automaticamente dados de diferentes fontes, identifica esquemas, classifica e armazena metadados no **AWS Glue Data Catalog**.  
  - **AWS ETL:** N√∫cleo do servi√ßo ETL, que gera c√≥digo Python ou Scala para realizar tarefas complexas de transforma√ß√£o de dados, como limpeza, enriquecimento e remo√ß√£o de duplicatas.  
  - **AWS Glue Data Catalog:** Armazena metadados de forma centralizada para consulta, transforma√ß√£o e rastreamento de dados. Funciona como uma "biblioteca" dos dados dispon√≠veis.  
- Permite extrair dados de fontes como **S3** e bancos de dados relacionais (**RDBMS**), transform√°-los e carreg√°-los em servi√ßos como **Amazon Redshift**.  
- Possui integra√ß√£o com outros servi√ßos AWS, como **Athena**, **Redshift** e **EMR**, para criar cat√°logos de dados reutiliz√°veis (**AWS Glue Data Catalog**).  
- Ideal para pipelines de dados complexos, prepara√ß√£o para an√°lises de *Big Data* e projetos de ci√™ncia de dados.  

![glue](assets/image-20210905124633707.png)

---

> **Integra√ß√£o com Servi√ßos AWS:**  
- **Athena:** Consultas SQL diretamente no cat√°logo de dados criado no Glue.  
- **Redshift:** Carregamento eficiente de dados transformados para an√°lises de data warehouse.  
- **EMR:** Integra√ß√£o para processamento distribu√≠do de grandes volumes de dados.  

![glue-catalog](assets/image-20210905124749244.png)

---

:::info **Detalhamento e Perguntas Frequentes**
- O AWS Glue √© **serverless**, ent√£o n√£o h√° necessidade de provisionar ou gerenciar servidores.  
- Utiliza o **Apache Spark** como mecanismo de execu√ß√£o para processar dados em escala.  
- Pode trabalhar com **Workflows** para encadear e gerenciar tarefas de ETL de forma orquestrada.  
- A integra√ß√£o com o **AWS Lake Formation** permite implementar controle de acesso baseado em permiss√µes no n√≠vel do cat√°logo de dados.  

üìå **Pergunta:** Uma empresa precisa transformar dados armazenados no S3 e carreg√°-los no Amazon Redshift para relat√≥rios anal√≠ticos. Qual a abordagem mais recomendada?  
- ‚úÖ Configurar um **AWS Glue Crawler** para catalogar os dados no S3, usar um script ETL do Glue para transforma√ß√£o e carregar os dados no Redshift.

üìå **Pergunta:** Um cientista de dados deseja consultar dados diretamente do cat√°logo de dados do Glue sem configurar um cluster EMR. Qual servi√ßo AWS pode ser utilizado?  
- ‚úÖ **Amazon Athena**, pois permite consultas SQL diretamente sobre os dados catalogados no Glue.

:::

---

## AWS Redshift  

- Servi√ßo de banco de dados para **Data Warehouse** da AWS, projetado para an√°lises em larga escala (OLAP - *Online Analytical Processing*).  
- Baseado no **PostgreSQL**, mas **n√£o √© adequado para transa√ß√µes OLTP** (*Online Transaction Processing*).  
- Processa dados em larga escala, com desempenho at√© **10 vezes superior** a outros sistemas OLAP, capaz de escalar para **petabytes (PB)** de dados.  
- Utiliza armazenamento em colunas e permite **execu√ß√£o massiva de consultas paralelas (MPP - Massively Parallel Processing)** para otimizar o processamento de grandes volumes de dados.  
- Modelo de pagamento baseado em inst√¢ncias provisionadas ‚Äî voc√™ paga apenas pelos recursos utilizados.  
- Suporta interface SQL para consultas, facilitando a integra√ß√£o com ferramentas de BI como **AWS QuickSight** ou **Tableau**.  

---

> **Redshift Workload Management (WLM):**  
  - Permite configurar m√∫ltiplas filas para otimizar a execu√ß√£o de diferentes cargas de trabalho.  
  - Exemplo: fila para superusu√°rio, fila para trabalhos curtos e fila para trabalhos longos.  
  - Pode ser ajustado manualmente ou configurado para ajuste autom√°tico.  
  - Minimiza o risco de bloqueio de tarefas r√°pidas por execu√ß√µes demoradas.  

---

> **Carga de Dados e Integra√ß√µes:**  
- Suporta carregamento de dados a partir de **Amazon S3**, **DynamoDB**, bancos de dados externos via **AWS DMS (Data Migration Service)** ou fluxos cont√≠nuos com **Kinesis Firehose**.  
- Pode escalar de **1 a 128 n√≥s**, com cada n√≥ tendo at√© **16 TB** de espa√ßo de armazenamento.  
- Estrutura de n√≥s:
  - **N√≥ l√≠der:** Planeja as consultas e agrega os resultados.  
  - **N√≥ de computa√ß√£o:** Executa as consultas e envia os resultados ao n√≥ l√≠der.  
  ![data-importe](assets/image-20210905122049485.png)

---

> **Recursos Adicionais:**  
- **Redshift Spectrum:** Permite executar consultas diretamente no **S3** sem necessidade de carregar os dados para dentro do cluster Redshift.  
  ![sprectrum](assets/image-20210905122151802.png)
- **Redshift Enhanced VPC Routing:** Permite que os dados sejam copiados e carregados atrav√©s da VPC, evitando tr√°fego de internet p√∫blica, aumentando a seguran√ßa.  
- **Snapshots:** S√£o realizados automaticamente a cada **8 horas**, a cada **5 GB** de dados modificados ou conforme agendamento manual.  
  - Os snapshots s√£o armazenados no **S3**.  
  - Para restaura√ß√µes de snapshots criptografados, √© necess√°rio copiar a chave KMS para o novo cluster.  
  ![image-20230221182853451](assets/image-20230221182853451.png)
- **Recupera√ß√£o de Desastres:**  
  - O Redshift n√£o √© Multi-AZ, ou seja, cada n√≥ est√° em uma √∫nica AZ (Zona de Disponibilidade).  
  - A recupera√ß√£o de desastres √© feita com base em snapshots armazenados no **S3**.  
  - Para alguns tipos de cluster, h√° suporte limitado a m√∫ltiplos n√≥s distribu√≠dos entre AZs.  

---

> **Cen√°rio de Utiliza√ß√£o:**  
- Ideal para cargas de trabalho anal√≠ticas de larga escala (OLAP) e n√£o para transa√ß√µes r√°pidas (OLTP).  
- Se as consultas forem espor√°dicas, √© recomend√°vel utilizar o **Amazon Athena**, que √© serverless e cobra apenas pelas consultas realizadas.  

---

> **Well-Architected para Redshift:**  
- Implementa√ß√£o de boas pr√°ticas para **seguran√ßa**, **otimiza√ß√£o de desempenho** e **custos**.  
  ![well-arch-redshift](assets/image-20210905122323552.png)

---

:::tip **Dica para a prova üéØ**


> Quest√µes relacionadas ao **Amazon Redshift** frequentemente exploram otimiza√ß√£o de performance, recupera√ß√£o de desastres e integra√ß√£o com outros servi√ßos da AWS.  

üìå Uma empresa precisa realizar an√°lises complexas e peri√≥dicas em um grande volume de dados armazenados no **Amazon S3**. Para evitar a necessidade de copiar os dados para o cluster do Redshift, qual recurso pode ser utilizado?  
- ‚úÖ **Amazon Redshift Spectrum**

üìå Durante a configura√ß√£o do Redshift, um administrador deseja garantir que consultas curtas n√£o fiquem presas aguardando a execu√ß√£o de tarefas longas. Como ele pode fazer isso?  
- ‚úÖ Configurando o **Redshift Workload Management (WLM)** para criar m√∫ltiplas filas de processamento.

---

> O **Redshift Enhanced VPC Routing** pode ser cobrado em quest√µes para verificar seu entendimento sobre a seguran√ßa de tr√°fego de dados.  

üìå Uma organiza√ß√£o deseja garantir que todo o tr√°fego de dados entre o Redshift e o **Amazon S3** ocorra dentro da rede privada da VPC. Qual recurso deve ser ativado?  
- ‚úÖ **Redshift Enhanced VPC Routing**

üìå Um snapshot criptografado de um cluster Redshift precisa ser restaurado em uma conta AWS diferente. O que √© necess√°rio para garantir que a restaura√ß√£o seja bem-sucedida?  
- ‚úÖ Certificar-se de que a chave **KMS** usada na criptografia esteja compartilhada com a nova conta.

---

> **Redshift vs Athena:** Certifique-se de entender as diferen√ßas entre esses servi√ßos, especialmente em rela√ß√£o a consultas espor√°dicas e cargas anal√≠ticas pesadas.  

üìå Um analista de dados precisa consultar periodicamente pequenos conjuntos de dados no S3, mas com uma carga de trabalho imprevis√≠vel. Qual servi√ßo √© mais adequado?  
- ‚úÖ **Amazon Athena**, pois cobra apenas pelas consultas realizadas, sendo mais econ√¥mico para cen√°rios espor√°dicos.

:::

---

## AWS Timestream  

- Servi√ßo de banco de dados para **s√©ries temporais** (**Time Series**), projetado para armazenar e analisar grandes volumes de dados temporais.
- Totalmente gerenciado pela AWS, com alta escalabilidade, desempenho otimizado e arquitetura **serverless** (sem necessidade de gerenciamento de servidores).
- Permite armazenar e analisar trilh√µes de registros de dados por dia.
- **1000 vezes mais r√°pido e 1/10 mais barato** que bancos de dados relacionais tradicionais para casos de uso espec√≠ficos de s√©ries temporais.
- Compat√≠vel com **SQL**, facilitando consultas anal√≠ticas complexas em dados temporais.
- Os dados recentes s√£o armazenados em mem√≥ria para consultas r√°pidas e, posteriormente, movidos para um armazenamento mais barato e dur√°vel.
- Oferece suporte para cria√ß√£o de fun√ß√µes anal√≠ticas de s√©ries temporais, como c√°lculos de m√©dia m√≥vel, agrega√ß√µes por janela de tempo e an√°lises preditivas.
- Possui criptografia em tr√¢nsito (TLS) e em repouso (integrado ao AWS KMS).
- **Casos de Uso:**  
  - Monitoramento de dispositivos IoT.  
  - An√°lise de dados em tempo real para sistemas de monitoramento de infraestrutura, telemetria e aplica√ß√µes financeiras.  
- Integra√ß√£o com outros servi√ßos AWS, como **IoT Core**, **Lambda**, **QuickSight** e **Grafana**, para visualiza√ß√£o e an√°lise de dados.  

![image-20230221185322425](assets/image-20230221185322425.png)

---

:::note **Nota Importante üîç**  
O **AWS Timestream** √© otimizado para leitura e escrita de grandes volumes de dados temporais, sendo ideal para cen√°rios onde a lat√™ncia baixa √© crucial. No entanto, n√£o √© adequado para transa√ß√µes complexas ou relacionamentos entre dados como um banco de dados relacional tradicional.  
[Documenta√ß√£o oficial do AWS Timestream](https://docs.aws.amazon.com/timestream/latest/developerguide/what-is-timestream.html)  
:::

---

:::tip **Dica para a prova üéØ**

> Quest√µes relacionadas ao **AWS Timestream** geralmente abordam sua aplica√ß√£o em cen√°rios de s√©ries temporais, integra√ß√£o com outros servi√ßos da AWS e compara√ß√£o de desempenho e custo com bancos de dados relacionais tradicionais.

üìå Uma empresa de monitoramento de dispositivos IoT precisa coletar dados de temperatura de milhares de sensores distribu√≠dos globalmente. Esses dados precisam ser processados e analisados em tempo real para ajustar condi√ß√µes ambientais. Qual solu√ß√£o AWS √© mais adequada para lidar com esse cen√°rio?  
- ‚úÖ AWS Timestream, devido √† capacidade de armazenar e consultar grandes volumes de dados temporais rapidamente.

---

> O **AWS Timestream** armazena dados recentes em mem√≥ria para consulta r√°pida e automaticamente migra para armazenamento mais barato √† medida que envelhecem. Quest√µes podem explorar o funcionamento dessa estrutura de armazenamento em camadas.

üìå Uma organiza√ß√£o precisa de um banco de dados para analisar dados hist√≥ricos de vendas para prever tend√™ncias futuras. O volume de dados √© alto e cresce diariamente. Qual servi√ßo da AWS √© recomendado para lidar com esse volume e fornecer respostas anal√≠ticas r√°pidas?  
- ‚úÖ AWS Timestream, pois √© otimizado para an√°lises de s√©ries temporais e dados hist√≥ricos.

---

> Quest√µes podem abordar a criptografia e a seguran√ßa dos dados no **AWS Timestream**, considerando conformidades de seguran√ßa e uso do AWS KMS.

üìå Uma empresa est√° preocupada com a seguran√ßa dos dados transmitidos para o AWS Timestream e precisa garantir criptografia em tr√¢nsito e em repouso. Qual abordagem o Timestream utiliza para garantir essa seguran√ßa?  
- ‚úÖ O AWS Timestream usa criptografia em tr√¢nsito com TLS e em repouso com integra√ß√£o ao AWS Key Management Service (KMS).

---

> O AWS Timestream se integra bem com outros servi√ßos da AWS, como IoT Core, Lambda e QuickSight, para visualiza√ß√£o e processamento em tempo real.  

üìå Um time de engenharia deseja visualizar dados de sensores em tempo real com gr√°ficos e dashboards din√¢micos. Qual a combina√ß√£o de servi√ßos AWS mais adequada para atingir esse objetivo?  
- ‚úÖ AWS Timestream para armazenamento e consulta, AWS IoT Core para ingest√£o de dados e AWS QuickSight para visualiza√ß√£o.

---

> O desempenho e a escalabilidade do AWS Timestream s√£o frequentemente comparados com bancos de dados relacionais tradicionais em quest√µes de prova.

üìå Um analista precisa armazenar e consultar dados de s√©ries temporais com alta frequ√™ncia de escrita e leitura. Por que o AWS Timestream seria preferido a um banco de dados relacional tradicional?  
- ‚úÖ Porque o AWS Timestream √© at√© **1000 vezes mais r√°pido** e at√© **10 vezes mais barato** para esse tipo de cen√°rio.

:::

---

## AWS Athena

![image-20230221185621707](assets/image-20230221185621707.png)

> Servi√ßo de consulta **Serverless** que permite realizar an√°lises diretamente em arquivos armazenados no **Amazon S3** utilizando **SQL**. Ideal para consultas ad hoc, an√°lises r√°pidas e integra√ß√£o com ferramentas de BI como **AWS QuickSight**.

---

> **Caracter√≠sticas principais:**  
- **Serverless:** N√£o requer provisionamento de infraestrutura ou gerenciamento de servidores.  
- **Linguagem SQL:** Realiza consultas nos dados diretamente no S3.  
- **Conectores JDBC e ODBC:** Possibilitam a conex√£o com ferramentas de BI e an√°lise de dados.  
- **Suporta m√∫ltiplos formatos de dados:** CSV, JSON, ORC, Avro, Parquet.  
- **Cobran√ßa baseada em uso:**  
  - **$5 por TB de dados escaneados.**  
  - Quanto mais eficiente a consulta (menos dados escaneados), menor o custo.  
- **Uso comum:** BI, Analytics, relat√≥rios, an√°lise de **VPC Flow Logs**, **ELB Logs** e an√°lise complexa com jun√ß√µes e fun√ß√µes de janela.  
- **Baseado em Presto:**  
  - O **Athena** usa o mecanismo de consulta distribu√≠do **Presto**, com suporte completo ao **SQL padr√£o**.  
  - Mais informa√ß√µes: [Presto na AWS](https://aws.amazon.com/pt/big-data/what-is-presto/).  

---

> **Integra√ß√£o com outros servi√ßos:**  
- **AWS QuickSight:** Para visualiza√ß√£o de dados e cria√ß√£o de dashboards interativos.  
- **Queries federadas:** Permitem consultar dados em outras fontes al√©m do S3 (RDS, DynamoDB, Redshift), utilizando fun√ß√µes Lambda para integra√ß√£o.  
- **Armazenamento de resultados no S3:** O resultado das queries pode ser armazenado diretamente no S3 para an√°lises futuras.  
- Possibilidade de se conectar a bancos de dados relacionais e NoSQL usando a Lambda como conector.  

---

> **Well-Architected:**  
- O Athena segue as pr√°ticas recomendadas do Well-Architected Framework da AWS para efici√™ncia de custo, performance e seguran√ßa.  
  ![athena-well-arch](assets/image-20210905115942523.png)

---

> **Melhorando a performance:**  
- Particione os dados no S3 para limitar a quantidade de dados escaneados.  
- Converta os dados para formatos colunarizados como **Parquet** ou **ORC** para melhorar a efici√™ncia de leitura.  
- Utilize compress√£o para reduzir o volume de dados e, consequentemente, o custo das queries.  
- Considere otimizar as consultas para evitar *full scans* desnecess√°rios.  
  ![image-20230221185907561](assets/image-20230221185907561.png)

---

:::info **Nota sobre pr√°ticas recomendadas**  
- Quando realizar queries ad hoc, utilize filtros de data ou parti√ß√µes para evitar a varredura de todo o dataset.  
- Avalie a aplica√ß√£o de **AWS Glue Data Catalog** para catalogar e organizar os metadados dos dados armazenados no S3, facilitando a consulta.  
- Para alta disponibilidade e consist√™ncia dos dados, sempre utilize buckets S3 configurados adequadamente, com versionamento habilitado.  
:::

---

:::tip **Dica para a prova üéØ**

> Quest√µes sobre o **AWS Athena** frequentemente pedem para identificar cen√°rios de uso adequado, integra√ß√£o com outras ferramentas de BI e otimiza√ß√£o de custos.  

üìå Uma empresa deseja realizar an√°lises ad hoc de grandes volumes de dados armazenados no Amazon S3, sem precisar gerenciar servidores. Qual servi√ßo da AWS √© mais indicado?  
- ‚úÖ **AWS Athena**

üìå Um time de dados est√° enfrentando custos elevados nas consultas do Athena devido √† varredura de grandes volumes de dados. Quais pr√°ticas podem ser adotadas para reduzir os custos?  
- ‚úÖ Particionar os dados no S3 e utilizar formatos colunarizados como **Parquet** ou **ORC**.

---

> Quest√µes tamb√©m podem abordar integra√ß√µes do Athena com outros servi√ßos da AWS, como **AWS Glue** para cataloga√ß√£o de dados.  

üìå Como o AWS Glue pode ser utilizado para otimizar as consultas do AWS Athena?  
- ‚úÖ Catalogando os dados no **AWS Glue Data Catalog**, facilitando a organiza√ß√£o e otimiza√ß√£o das queries.

üìå Qual √© o mecanismo de consulta subjacente ao Athena, conhecido por sua alta performance em an√°lise distribu√≠da de grandes volumes de dados?  
- ‚úÖ **Presto**, com suporte completo ao SQL padr√£o.

:::

---

## AWS QuickSight

![Como o Quicksight funciona](assets/026e51297c1fa18b850ce2ffc1575a9124bbad16.png)

> **Vis√£o Geral:**  

O **AWS QuickSight** √© um servi√ßo de intelig√™ncia comercial (BI) totalmente gerenciado, escal√°vel e alimentado por machine learning. Ele permite criar e compartilhar pain√©is interativos e insights visuais rapidamente, sendo ideal para an√°lise de dados baseada na nuvem.

---

> **Caracter√≠sticas Principais:**  
- Servi√ßo de BI **serverless**, escal√°vel e incorpor√°vel.  
- Utiliza **Machine Learning** para criar insights autom√°ticos.  
- **Modelo de pagamento:** "Pay-per-session" ‚Äî voc√™ paga apenas pelas sess√µes ativas de uso.  
- Controle de acesso via **usu√°rios ou grupos**, que podem ser gerenciados fora do IAM, facilitando a administra√ß√£o.  
- Baseado no mecanismo de c√°lculos paralelos em mem√≥ria chamado **SPICE** (Super-fast, Parallel, In-memory Calculation Engine), otimizando consultas e melhorando o desempenho.  
- Oferece **Column-Level Security (CLS)** ‚Äî controle de acesso a n√≠vel de coluna para restringir visualiza√ß√£o de dados sens√≠veis.  

> **Conex√µes e Fontes de Dados:**  
O QuickSight pode se conectar a diversas fontes de dados, incluindo:  
- Bancos de dados gerenciados da AWS como **Aurora** e **RDS**.  
- Servi√ßos anal√≠ticos como **Athena** e **S3**.  

![Fontes de Dados QuickSight](assets/image-20230221191125886.png)

---

> **Vantagens e Casos de Uso:**  
- Cria√ß√£o r√°pida de **dashboards interativos** para visualiza√ß√£o de dados.  
- An√°lises avan√ßadas com o uso de machine learning para detectar anomalias e prever tend√™ncias.  
- Uso compartilhado para equipes internas ou clientes externos com autentica√ß√£o segura e acesso controlado.  
- An√°lise integrada com outras ferramentas de dados da AWS, como **Athena** e **Redshift**.  

---

:::info **Nota sobre Seguran√ßa e Governan√ßa**  
- O uso do **CLS (Column-Level Security)** √© essencial para proteger dados sens√≠veis e garantir conformidade com regulamenta√ß√µes.  
- O gerenciamento de usu√°rios e permiss√µes fora do IAM pode simplificar o acesso para grandes equipes de an√°lise ou clientes externos.  
- O SPICE permite a manipula√ß√£o de grandes volumes de dados com alta performance, sendo uma alternativa eficiente para queries pesadas.  
:::

---

> Well-Architected

Ao integrar o QuickSight em uma arquitetura bem planejada, considere:  
- Utilizar o **AWS Glue Data Catalog** para organiza√ß√£o de dados.  
- Aplicar boas pr√°ticas de seguran√ßa no armazenamento dos dados no S3.  
- Monitorar e controlar os custos do modelo **Pay-per-session**, especialmente em equipes grandes.  

---

:::tip **Dica para a prova üéØ**

> Quest√µes sobre o **AWS QuickSight** geralmente envolvem integra√ß√£o com fontes de dados AWS, estrat√©gias de seguran√ßa como o **Column-Level Security (CLS)** e otimiza√ß√£o de custos no modelo **Pay-per-session**.

üìå Uma equipe de an√°lise deseja criar pain√©is interativos no QuickSight usando dados armazenados no **Amazon Athena** e **S3**, sem precisar configurar um servidor. Qual caracter√≠stica do QuickSight torna isso poss√≠vel?  
- ‚úÖ O QuickSight √© um servi√ßo **serverless** com suporte a m√∫ltiplas fontes de dados da AWS.  

üìå Um cliente deseja garantir que apenas membros espec√≠ficos da equipe possam visualizar colunas sens√≠veis em um painel do QuickSight. Qual recurso deve ser configurado?  
- ‚úÖ **Column-Level Security (CLS)** para controle de acesso a n√≠vel de coluna.  

---

> O modelo de precifica√ß√£o do QuickSight pode gerar custos inesperados se n√£o gerenciado corretamente, especialmente para equipes grandes ou acessos externos.

üìå Uma organiza√ß√£o deseja fornecer acesso espor√°dico a relat√≥rios de BI para uma equipe de 200 pessoas. Qual estrat√©gia de precifica√ß√£o seria mais econ√¥mica no QuickSight?  
- ‚úÖ Utilizar o modelo **Pay-per-session**, pagando apenas pelos acessos efetivos.  

üìå Um analista precisa integrar o QuickSight a dados armazenados no **Amazon Aurora** para criar pain√©is interativos. Quais permiss√µes devem ser concedidas para essa integra√ß√£o?  
- ‚úÖ Permiss√£o no IAM para leitura dos dados no Amazon Aurora e acesso ao QuickSight.  

:::

---

## Executando Jobs na AWS

- A AWS oferece diversas solu√ß√µes para execu√ß√£o de jobs, variando de acordo com a demanda e o n√≠vel de gerenciamento necess√°rio. A escolha correta depende de fatores como **tempo de execu√ß√£o**, **escalabilidade** e **complexidade de implementa√ß√£o**.

> Exemplos de solu√ß√µes para execu√ß√£o de jobs:

1. **EC2 (Amazon Elastic Compute Cloud)**
   - Ideal para longas execu√ß√µes, mas requer gerenciamento de infraestrutura.
   - N√£o escala automaticamente de forma nativa; precisa de configura√ß√µes adicionais com Auto Scaling.
  
2. **AWS Lambda**
   - Escal√°vel e gerenciado, por√©m limitado a um tempo m√°ximo de execu√ß√£o de **15 minutos**.
   - Bom para tarefas curtas e baseadas em eventos, como ETL em tempo real.

3. **AWS Step Functions**
   - Orquestra√ß√£o de workflows serverless com AWS Lambda.
   - Reage a eventos complexos, mas herda a limita√ß√£o de tempo do Lambda.

4. **AWS Batch**
   - Ideal para jobs longos, processando em larga escala.
   - Suporte para workloads com grande volume de dados; complexidade maior para configurar.

5. **AWS Fargate**
   - Executa cont√™ineres sem necessidade de gerenciamento de infraestrutura.
   - Bom para jobs longos e workloads event-driven.

6. **EMR (Elastic MapReduce)**
   - Usado para grandes volumes de dados no estilo Big Data.
   - Baseado no Hadoop e Apache Spark, sendo mais complexo e custoso.

![Exemplo de execu√ß√£o de jobs](assets/image-20230221180929791.png)

:::note üîé **Observa√ß√£o**
Para workloads de Big Data, o **AWS EMR** √© recomendado, enquanto jobs event-driven e curtos s√£o mais adequados para o **AWS Lambda**.
:::

---

### Pipelines para trabalhar com dados

A AWS oferece diversas ferramentas e abordagens para pipelines de dados. A escolha depende do caso de uso, seja **an√°lise de dados**, **ingest√£o de grandes volumes** ou compara√ß√£o de tecnologias.

> **An√°lise de dados:** Identificar tend√™ncias e insights com rapidez.  
![An√°lise de dados](assets/image-20230221191437913.png)

> **Ingest√£o de dados Big Data:** Processar grandes volumes de dados de maneira escal√°vel.  
![Ingest√£o de dados Big Data](assets/image-20230221191554977.png)

> **Compara√ß√£o de tecnologias:** Identificar a melhor abordagem com base nos requisitos do projeto.  
![Compara√ß√£o de tecnologias](assets/image-20230221191808657.png)

---

> **Explica√ß√µes Adicionais**

- **AWS Glue:** Servi√ßo de ETL serverless, recomendado para processar e mover dados entre servi√ßos AWS.
- **Amazon Kinesis:** Excelente para ingest√£o de dados em tempo real.
- **AWS Data Pipeline:** Permite orquestrar e automatizar a movimenta√ß√£o de dados e processos peri√≥dicos.
- **Amazon Redshift:** An√°lise de dados estruturados em grande escala.

:::info üí° **Detalhamento Importante**
√â fundamental entender os casos de uso ideais de cada ferramenta para escolher a melhor op√ß√£o em uma arquitetura de Big Data.
:::
